{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Boosting Techniques"
      ],
      "metadata": {
        "id": "jzQdUTJNN3_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1: What is Boosting in Machine Learning? Explain how it improves weak**"
      ],
      "metadata": {
        "id": "loF6u1L9N7fN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boosting is an ensemble learning technique in machine learning that combines multiple weak learners to create a strong predictive model. A weak learner is a model that performs only slightly better than random guessing (for example, a shallow decision tree).\n",
        "\n",
        "**Key Idea of Boosting**\n",
        "\n",
        "The main idea behind boosting is to train models sequentially, where:\n",
        "\n",
        "- Each new model focuses more on the errors made by previous models\n",
        "\n",
        "- Misclassified data points are given higher importance (weights)\n",
        "\n",
        "- Correctly classified points receive lower importance\n",
        "\n",
        "By doing this, the ensemble gradually improves its performance.\n",
        "\n",
        "**How Boosting Improves Weak Learners**\n",
        "\n",
        "**1. Sequential Learning**\n",
        "\n",
        "Models are trained one after another, not independently.\n",
        "Each model learns from the mistakes of the previous one.\n",
        "\n",
        "**2. Focus on Difficult Samples**\n",
        "\n",
        "Data points that are misclassified are given more attention in later models, helping the ensemble learn complex patterns.\n",
        "\n",
        "**3. Weighted Contribution**\n",
        "\n",
        "Each weak learner is assigned a weight based on its accuracy.\n",
        "More accurate models have a stronger influence on the final prediction.\n",
        "\n",
        "**4. Error Reduction**\n",
        "\n",
        "Boosting reduces bias and can also reduce variance, leading to better overall accuracy.\n",
        "\n",
        "##- **Common Boosting Algorithms**\n",
        "\n",
        "- AdaBoost (Adaptive Boosting)\n",
        "\n",
        "- Gradient Boosting\n",
        "\n",
        "- XGBoost\n",
        "\n",
        "- LightGBM\n",
        "\n",
        "**Advantages of Boosting**\n",
        "\n",
        "- Converts weak learners into a strong learner\n",
        "\n",
        "- High predictive accuracy\n",
        "\n",
        "- Handles complex, non-linear relationships well\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Boosting is an ensemble technique that improves weak learners by training models sequentially and focusing more on previously misclassified data points. By combining multiple weak models in a weighted manner, boosting creates a powerful and accurate prediction system."
      ],
      "metadata": {
        "id": "UCFUGuKoN_rC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2: What is the difference between AdaBoost and Gradient Boosting in terms of how models are trained?**"
      ],
      "metadata": {
        "id": "g0UyXR6aPnWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBoost and Gradient Boosting are both boosting algorithms, but they differ in how they train models and handle errors.\n",
        "\n",
        "\n",
        "**Difference Between AdaBoost and Gradient Boosting**\n",
        "\n",
        "\n",
        "| Aspect                 | **AdaBoost**                                               | **Gradient Boosting**                                     |\n",
        "| ---------------------- | ---------------------------------------------------------- | --------------------------------------------------------- |\n",
        "| **Training Approach**  | Trains models sequentially by **re-weighting data points** | Trains models sequentially by **fitting residual errors** |\n",
        "| **Focus on Errors**    | Increases weights of **misclassified samples**             | Learns from **residuals (errors)** of previous models     |\n",
        "| **Loss Function**      | Uses **exponential loss**                                  | Can use **any differentiable loss function**              |\n",
        "| **Model Contribution** | Assigns **weights to models** based on accuracy            | Models contribute via **gradient descent optimization**   |\n",
        "| **Flexibility**        | Less flexible                                              | More flexible and powerful                                |\n",
        "| **Handling Noise**     | Sensitive to outliers                                      | More robust with proper regularization                    |\n",
        "\n",
        "\n",
        "**Training Process Explained Simply**\n",
        "\n",
        "**AdaBoost:**\n",
        "\n",
        "Each new model gives more importance to incorrectly classified samples from the previous model.\n",
        "\n",
        "**Gradient Boosting:**\n",
        "\n",
        "Each new model is trained to correct the residual errors by minimizing a loss function using gradient descent.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "AdaBoost improves performance by increasing the weights of misclassified data points, while Gradient Boosting improves performance by fitting models to the residual errors using gradient descent. Gradient Boosting is more flexible due to its ability to optimize different loss functions."
      ],
      "metadata": {
        "id": "TXU46pZ5PrWQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3: How does regularization help in XGBoost?**"
      ],
      "metadata": {
        "id": "lzz1arY0QVOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularization in **XGBoost** helps prevent **overfitting** by controlling the complexity of the model. It penalizes overly complex trees so that the model generalizes better to unseen data.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Ways Regularization Helps in XGBoost**\n",
        "\n",
        "1. **Controls Tree Complexity**\n",
        "   XGBoost adds penalties for:\n",
        "\n",
        "   * **Number of leaves**\n",
        "   * **Large leaf weights**\n",
        "\n",
        "   This discourages the model from creating very deep or complex trees.\n",
        "\n",
        "2. **L1 and L2 Regularization**\n",
        "\n",
        "   * **L1 (alpha)**: Encourages sparsity by reducing less important feature weights to zero.\n",
        "   * **L2 (lambda)**: Shrinks weights smoothly to prevent large coefficients.\n",
        "\n",
        "3. **Prevents Overfitting**\n",
        "   By penalizing complexity, the model focuses on **important patterns** instead of noise.\n",
        "\n",
        "4. **Improves Generalization**\n",
        "   Regularization ensures the model performs well on **new, unseen data**, not just the training set.\n",
        "\n",
        "---\n",
        "\n",
        "### **Important Regularization Parameters in XGBoost**\n",
        "\n",
        "| Parameter          | Purpose                               |\n",
        "| ------------------ | ------------------------------------- |\n",
        "| `alpha`            | L1 regularization (feature selection) |\n",
        "| `lambda`           | L2 regularization (weight shrinkage)  |\n",
        "| `max_depth`        | Limits tree depth                     |\n",
        "| `min_child_weight` | Controls minimum samples per leaf     |\n",
        "| `gamma`            | Minimum loss reduction for a split    |\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion**\n",
        "\n",
        "> Regularization in XGBoost reduces overfitting by penalizing complex trees and large weights, helping the model generalize better to unseen data."
      ],
      "metadata": {
        "id": "OBfu6k6QQYbv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 4: Why is CatBoost considered efficient for handling categorical data?**\n",
        "\n",
        "CatBoost is considered highly efficient for handling categorical data because it can process categorical features **directly**, without requiring extensive manual preprocessing such as one-hot encoding or label encoding.\n",
        "\n",
        "\n",
        "### **Reasons CatBoost Is Efficient for Categorical Data**\n",
        "\n",
        "1. **Native Handling of Categorical Features**\n",
        "   CatBoost automatically converts categorical variables into numerical representations using advanced encoding techniques, so there is no need for one-hot encoding.\n",
        "\n",
        "2. **Target-Based Encoding**\n",
        "   It uses **ordered target statistics** to encode categorical features, which reduces information leakage and improves model accuracy.\n",
        "\n",
        "3. **Prevents Overfitting**\n",
        "   The ordered boosting mechanism ensures that encoding is done using only past data during training, helping prevent overfitting.\n",
        "\n",
        "4. **Handles High Cardinality Features Well**\n",
        "   CatBoost performs efficiently even when categorical features have many unique values (e.g., user IDs, city names).\n",
        "\n",
        "5. **Less Feature Engineering Required**\n",
        "   Since CatBoost handles categorical data internally, it reduces preprocessing time and human effort.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Advantages (Summary Table)**\n",
        "\n",
        "| Feature                       | Benefit                         |\n",
        "| ----------------------------- | ------------------------------- |\n",
        "| Built-in categorical handling | No manual encoding needed       |\n",
        "| Ordered boosting              | Reduces target leakage          |\n",
        "| High-cardinality support      | Works well with many categories |\n",
        "| Automatic preprocessing       | Faster model development        |\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion**\n",
        "\n",
        " CatBoost is efficient for categorical data because it natively handles categorical features using target-based encoding and ordered boosting, reducing preprocessing effort and preventing overfitting."
      ],
      "metadata": {
        "id": "Vd0Cu25hQiQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 5: Real-world applications where Boosting is preferred over Bagging**\n",
        "\n",
        "Boosting techniques are preferred over bagging methods when the goal is to **improve accuracy by focusing on hard-to-predict cases** and **reduce bias**, especially in complex or imbalanced datasets.\n",
        "\n",
        "\n",
        "### **Real-world Applications of Boosting**\n",
        "\n",
        "1. **Credit Risk & Loan Default Prediction (Banking)**\n",
        "   Boosting models like XGBoost and AdaBoost focus on misclassified defaulters, improving prediction accuracy for high-risk customers.\n",
        "\n",
        "2. **Fraud Detection**\n",
        "   Fraud cases are rare and difficult to detect. Boosting gives more weight to misclassified fraudulent transactions, making it ideal for imbalanced datasets.\n",
        "\n",
        "3. **Medical Diagnosis**\n",
        "   Used in disease prediction (cancer detection, heart disease) where small improvements in accuracy are critical. Boosting improves weak models by learning from errors.\n",
        "\n",
        "4. **Customer Churn Prediction**\n",
        "   Boosting helps identify subtle patterns in customer behavior that simple models may miss, improving churn prediction accuracy.\n",
        "\n",
        "5. **Search Ranking & Recommendation Systems**\n",
        "   Gradient Boosting models are widely used to rank search results and recommend content by learning complex feature interactions.\n",
        "\n",
        "6. **Image & Face Detection**\n",
        "   AdaBoost is famously used in face detection systems (e.g., Viola-Jones algorithm) due to its ability to combine many weak learners.\n",
        "\n",
        "### **Why Boosting Over Bagging in These Cases**\n",
        "\n",
        "| Aspect                         | Boosting       | Bagging        |\n",
        "| ------------------------------ | -------------- | -------------- |\n",
        "| Focus on errors                | Yes            | No             |\n",
        "| Bias reduction                 | High           | Low            |\n",
        "| Works well on complex patterns | Yes            | Moderate       |\n",
        "| Imbalanced data                | Very effective | Less effective |\n",
        "\n",
        "### **Conclusion**\n",
        "\n",
        "Boosting techniques are preferred in applications like fraud detection, credit risk assessment, medical diagnosis, and recommendation systems because they reduce bias by focusing on difficult cases and improving weak learners iteratively."
      ],
      "metadata": {
        "id": "S-7JxFXqQyQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 6: Train an AdaBoost Classifier on the Breast Cancer dataset and print accuracy**"
      ],
      "metadata": {
        "id": "29m8hmWYRkWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train AdaBoost Classifier\n",
        "model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"AdaBoost Classifier Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcixleUORksb",
        "outputId": "ddec507a-a5b1-4a2c-d555-4670f4431098"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Classifier Accuracy: 0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Conclusion**\n",
        "\n",
        " The AdaBoost Classifier achieves high accuracy on the Breast Cancer dataset, showing its effectiveness in improving classification performance by combining weak learners."
      ],
      "metadata": {
        "id": "Wo5v_cxoQ_bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7: Write a Python program to:**\n",
        "\n",
        "**● Train a Gradient Boosting Regressor on the California Housing dataset**\n",
        "\n",
        "**● Evaluate performance using R-squared score**"
      ],
      "metadata": {
        "id": "i8Sv0q7CSBK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Step 1: Load California Housing dataset\n",
        "california = fetch_california_housing()\n",
        "X = california.data\n",
        "y = california.target\n",
        "\n",
        "# Step 2: Split dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Initialize Gradient Boosting Regressor\n",
        "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# Step 4: Train the model\n",
        "gbr.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Predict on test set\n",
        "y_pred = gbr.predict(X_test)\n",
        "\n",
        "# Step 6: Evaluate model performance using R-squared score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R-squared score on test set: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c6qpfacSJZG",
        "outputId": "8f009047-1f5c-432c-9633-07a89fdaf45d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared score on test set: 0.7756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation:**\n",
        "\n",
        "1. **Dataset:** `fetch_california_housing()` provides features like median income, house age, and population, with the target being the median house value.\n",
        "2. **Train-test split:** 80% of data for training, 20% for testing.\n",
        "3. **Gradient Boosting Regressor:** Ensemble method that builds trees sequentially, optimizing residual errors.\n",
        "4. **Evaluation:** `r2_score` tells how well the model predicts; closer to 1 is better.\n"
      ],
      "metadata": {
        "id": "r78DTeIgSQuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8: Write a Python program to:**\n",
        "\n",
        "**● Train an XGBoost Classifier on the Breast Cancer dataset**\n",
        "\n",
        "**● Tune the learning rate using GridSearchCV**\n",
        "\n",
        "**● Print the best parameters and accuracy**"
      ],
      "metadata": {
        "id": "PslLFOQmSYjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Initialize XGBoost Classifier\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Step 4: Define parameter grid for learning rate\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3]\n",
        "}\n",
        "\n",
        "# Step 5: Set up GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Step 6: Train model with GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 7: Get best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best learning rate: {best_params['learning_rate']}\")\n",
        "\n",
        "# Step 8: Predict on test set using the best estimator\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Step 9: Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy on test set: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8eg_2rySkmN",
        "outputId": "34f4513e-0d64-4233-fcc2-951887c350ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best learning rate: 0.2\n",
            "Accuracy on test set: 0.9561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [16:43:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation:**\n",
        "\n",
        "1. **Dataset:** `load_breast_cancer()` provides features of tumors and target labels (malignant vs benign).\n",
        "2. **XGBoost Classifier:** Powerful gradient boosting algorithm for classification tasks.\n",
        "3. **GridSearchCV:** Tries different learning rates (`0.01, 0.05, 0.1, 0.2, 0.3`) with 5-fold cross-validation to find the best one.\n",
        "4. **Accuracy:** Evaluates the performance of the best model on the test set."
      ],
      "metadata": {
        "id": "Ko7SlmRtSmxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9: Write a Python program to:**\n",
        "\n",
        "**● Train a CatBoost Classifier**\n",
        "\n",
        "**● Plot the confusion matrix using seaborn**"
      ],
      "metadata": {
        "id": "IEDts37ZS68w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Step 2: Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Initialize CatBoost Classifier\n",
        "cat_model = CatBoostClassifier(iterations=500, learning_rate=0.1, depth=4, verbose=0, random_state=42)\n",
        "\n",
        "# Step 4: Train the model\n",
        "cat_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Predict on test set\n",
        "y_pred = cat_model.predict(X_test)\n",
        "\n",
        "# Step 6: Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Step 7: Plot confusion matrix using seaborn\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - CatBoost Classifier')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "id": "d1hIuVPvTF5m",
        "outputId": "bedf01dd-4b83-4561-d7b6-0cd9f8b50a40"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.3.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAGJCAYAAACTqKqrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATeJJREFUeJzt3XlcVNX7B/DPgDDsgyCryuIGaGpJLoh7GJq5gWumuJRluIHmUrlWUprivpuapeaWmeWCikuKO+aOuIUpi6KAoAzb+f3hz/k6gsoAw4x3Pu9e9xVz7nKeuc30zDn33HNlQggBIiIieu0Z6ToAIiIiKhtM6kRERBLBpE5ERCQRTOpEREQSwaROREQkEUzqREREEsGkTkREJBFM6kRERBLBpE5ERCQRTOoSFB8fj3fffRcKhQIymQxbt24t0+PfvHkTMpkMq1atKtPjvs5atWqFVq1a6ToM0jJ9+Ox7eHigf//+amVFfedXrVoFmUyGmzdv6iRO0g0mdS25du0aPvnkE1SrVg1mZmawsbGBv78/5syZg8ePH2u17pCQEJw7dw7ffvst1qxZg7ffflur9ZWn/v37QyaTwcbGpsjzGB8fD5lMBplMhh9++EHj49+5cweTJ0/GmTNnyiDa8pOfn4+VK1eiVatWsLOzg1wuh4eHBwYMGICTJ09qfLyLFy9i8uTJRSaEVq1aqc6xTCaDqakpPD09MXjwYNy6dasM3k3pHDlyBJMnT0ZaWppG++3fvx9BQUFwdnaGqakpHB0d0bFjR2zZskU7gZYhKX/nSUOCytz27duFubm5sLW1FcOHDxdLly4V8+fPF7169RImJibi448/1lrdjx49EgDEl19+qbU6CgoKxOPHj0VeXp7W6niRkJAQUaFCBWFsbCx+/fXXQusnTZokzMzMBAAxY8YMjY9/4sQJAUCsXLlSo/2USqVQKpUa11cWHj16JNq1aycAiBYtWogZM2aIFStWiAkTJggvLy8hk8nErVu3NDrmxo0bBQARHR1daF3Lli1FlSpVxJo1a8SaNWvEihUrxKhRo4SlpaVwc3MTWVlZZfTOSmbGjBkCgLhx40ax95k4caIAIGrWrCkmTpwoVqxYIaZPny5atWolAIhffvlFCCHEjRs3SvT5KEvZ2dkiJydH9fpF3/m8vDzx+PFjUVBQUN4hkg5V0NWPCam6ceMGevXqBXd3d+zbtw8uLi6qdaGhobh69Sr+/PNPrdV/9+5dAICtra3W6pDJZDAzM9Pa8V9FLpfD398f69atQ48ePdTWrV27Fh06dMDmzZvLJZZHjx7BwsICpqam5VJfUT7//HPs3LkTkZGRGDlypNq6SZMmITIysszrVCgU+PDDD9XKPD09MXToUBw+fBht27Yt8zq1ZdOmTZg6dSq6deuGtWvXwsTERLXu888/x65du5Cbm6vDCNXJ5XK11y/6zhsbG8PY2LjM6s3KyoKlpWWZHY+0RNe/KqTm008/FQDE4cOHi7V9bm6umDp1qqhWrZowNTUV7u7uYvz48SI7O1ttO3d3d9GhQwdx6NAh0bBhQyGXy4Wnp6dYvXq1aptJkyYJAGqLu7u7EOJJC/fp3896us+zdu/eLfz9/YVCoRCWlpaiVq1aYvz48ar1L2qt7N27VzRr1kxYWFgIhUIhOnXqJC5evFhkffHx8SIkJEQoFAphY2Mj+vfvX6wWXkhIiLC0tBSrVq0ScrlcPHjwQLXu+PHjAoDYvHlzoZZ6amqqGDVqlHjjjTeEpaWlsLa2Fu3atRNnzpxRbRMdHV3o/D37Plu2bCnq1KkjTp48KZo3by7Mzc3FiBEjVOtatmypOla/fv2EXC4v9P7fffddYWtrK27fvv3K91oct27dEhUqVBBt27Yt1vY3b94UQ4YMEbVq1RJmZmbCzs5OdOvWTa1Vu3LlyiLPw9NW+9Pz8LxNmzYJAGLfvn1q5adPnxbt2rUT1tbWwtLSUrRp00bExMQU2v/atWuiW7duomLFisLc3Fw0btxYbN++vdB2c+fOFbVr11b1hvn6+qpa0kV9B/CKVru3t7ews7MTGRkZrzx/RX32//nnHxESEiI8PT2FXC4XTk5OYsCAAeLevXtq+2ZkZIgRI0YId3d3YWpqKhwcHERAQIA4deqUapsrV66IoKAg4eTkJORyuahcubLo2bOnSEtLU23j7u4uQkJCXvh+n37Pn/53fP69//XXX6rvqZWVlXjvvffE+fPn1bZ5+j27evWqaN++vbCyshKdO3d+5fkh3WNLvYz98ccfqFatGpo2bVqs7T/66COsXr0a3bp1w6hRo3Ds2DFERETg0qVL+O2339S2vXr1Krp164ZBgwYhJCQEP/74I/r37w9fX1/UqVMHQUFBsLW1RVhYGHr37o333nsPVlZWGsV/4cIFvP/++6hXrx6mTp0KuVyOq1ev4vDhwy/db8+ePWjfvj2qVauGyZMn4/Hjx5g3bx78/f1x+vRpeHh4qG3fo0cPeHp6IiIiAqdPn8by5cvh6OiI77//vlhxBgUF4dNPP8WWLVswcOBAAE9a6d7e3mjQoEGh7a9fv46tW7eie/fu8PT0RHJyMpYsWYKWLVvi4sWLcHV1hY+PD6ZOnYqJEydi8ODBaN68OQCo/bdMTU1F+/bt0atXL3z44YdwcnIqMr45c+Zg3759CAkJQUxMDIyNjbFkyRLs3r0ba9asgaura7He56vs2LEDeXl56Nu3b7G2P3HiBI4cOYJevXqhSpUquHnzJhYtWoRWrVrh4sWLsLCwQIsWLTB8+HDMnTsXX3zxBXx8fABA9W/gyTX8e/fuAQByc3Nx6dIlTJo0CTVq1IC/v79quwsXLqB58+awsbHBmDFjYGJigiVLlqBVq1Y4cOAAGjduDABITk5G06ZN8ejRIwwfPhz29vZYvXo1OnXqhE2bNqFr164AgGXLlmH48OHo1q0bRowYgezsbJw9exbHjh3DBx98gKCgIFy5cgXr1q1DZGQkKlWqBABwcHAo8nzEx8fj8uXLGDhwIKytrTU8+09ERUXh+vXrGDBgAJydnXHhwgUsXboUFy5cwNGjRyGTyQAAn376KTZt2oShQ4eidu3aSE1Nxd9//41Lly6hQYMGyMnJQWBgIJRKJYYNGwZnZ2fcvn0b27dvR1paGhQKRaG6Nf3Or1mzBiEhIQgMDMT333+PR48eYdGiRWjWrBliY2PVvqd5eXkIDAxEs2bN8MMPP8DCwqJE54fKma5/VUhJenq6AFDsX7RnzpwRAMRHH32kVj569OhCLR53d3cBQBw8eFBVlpKSIuRyuRg1apSq7GlL4vnrycVtqUdGRgoA4u7duy+Mu6jWyptvvikcHR1Famqqquyff/4RRkZGol+/foXqGzhwoNoxu3btKuzt7V9Y57Pvw9LSUgghRLdu3cQ777wjhBAiPz9fODs7iylTphR5DrKzs0V+fn6h9yGXy8XUqVNVZS+7pt6yZUsBQCxevLjIdc+21IUQYteuXQKA+Oabb8T169eFlZWV6NKlyyvfoybCwsIEABEbG1us7R89elSoLCYmRgAQP/30k6rsVdfUUURr2MfHR1y/fl1t2y5dughTU1Nx7do1VdmdO3eEtbW1aNGihaps5MiRAoA4dOiQquzhw4fC09NTeHh4qP7bde7cuchegmdpck39999/FwBEZGTkK7cVoujPflHndN26dYW+rwqFQoSGhr7w2LGxsQKA2Lhx40tjeLal/mxMz3/nn2+pP3z4UNja2hYa05OUlCQUCoVaeUhIiAAgxo0b99JYSP9w9HsZysjIAIBi/+L/66+/AADh4eFq5aNGjQKAQtfea9eurWo9Ak9aH15eXrh+/XqJY37e0+tyv//+OwoKCoq1T2JiIs6cOYP+/fvDzs5OVV6vXj20bdtW9T6f9emnn6q9bt68OVJTU1XnsDg++OAD7N+/H0lJSdi3bx+SkpLwwQcfFLmtXC6HkdGTj3t+fj5SU1NhZWUFLy8vnD59uth1yuVyDBgwoFjbvvvuu/jkk08wdepUBAUFwczMDEuWLCl2XcWh6WfO3Nxc9Xdubi5SU1NRo0YN2NraanQePDw8EBUVhaioKOzYsQOzZ89Geno62rdvr7rGm5+fj927d6NLly6oVq2aal8XFxd88MEH+Pvvv1Xx//XXX2jUqBGaNWum2s7KygqDBw/GzZs3cfHiRQBPPp///fcfTpw4UexYX0bT81eUZ89pdnY27t27hyZNmgCA2jm1tbXFsWPHcOfOnSKP87QlvmvXLjx69KjE8bxIVFQU0tLS0Lt3b9y7d0+1GBsbo3HjxoiOji60z5AhQ8o8DtIuJvUyZGNjAwB4+PBhsbb/999/YWRkhBo1aqiVOzs7w9bWFv/++69auZubW6FjVKxYEQ8ePChhxIX17NkT/v7++Oijj+Dk5IRevXphw4YNL03wT+P08vIqtM7Hxwf37t1DVlaWWvnz76VixYoAoNF7ee+992BtbY1ff/0Vv/zyCxo2bFjoXD5VUFCAyMhI1KxZE3K5HJUqVYKDgwPOnj2L9PT0YtdZuXJljQbF/fDDD7Czs8OZM2cwd+5cODo6vnKfu3fvIikpSbVkZma+cFtNP3OPHz/GxIkTUbVqVbXzkJaWptF5sLS0REBAAAICAtCuXTuMGDEC27ZtQ1xcHL777jvV+3j06NELPxcFBQWqW+D+/fffF273dD0AjB07FlZWVmjUqBFq1qyJ0NDQV14aehlNz19R7t+/jxEjRsDJyQnm5uZwcHCAp6cnAKid0+nTp+P8+fOoWrUqGjVqhMmTJ6v9IPf09ER4eDiWL1+OSpUqITAwEAsWLNDov8vLxMfHAwDatGkDBwcHtWX37t1ISUlR275ChQqoUqVKmdRN5YdJvQzZ2NjA1dUV58+f12i/p9fcXuVFI1mFECWuIz8/X+21ubk5Dh48iD179qBv3744e/YsevbsibZt2xbatjRK816eksvlCAoKwurVq/Hbb7+9sJUOANOmTUN4eDhatGiBn3/+Gbt27UJUVBTq1KlT7B4JQL1VVhyxsbGq/1meO3euWPs0bNgQLi4uquVl99t7e3trdOxhw4bh22+/RY8ePbBhwwbs3r0bUVFRsLe31+g8FMXX1xcKhQIHDx4s1XFexsfHB3FxcVi/fj2aNWuGzZs3o1mzZpg0aVKJjqfp+StKjx49sGzZMtUYj927d2Pnzp0AoHZOe/TogevXr2PevHlwdXXFjBkzUKdOHezYsUO1zcyZM3H27Fl88cUXePz4MYYPH446dergv//+K3F8Tz2NZc2aNapelmeX33//XW37Z3u36PXBgXJl7P3338fSpUsRExMDPz+/l27r7u6OgoICxMfHqw1CSk5ORlpaGtzd3cssrooVKxY5GcfzvQEAYGRkhHfeeQfvvPMOZs2ahWnTpuHLL79EdHQ0AgICinwfABAXF1do3eXLl1GpUiWt3QrzwQcf4Mcff4SRkRF69er1wu02bdqE1q1bY8WKFWrlaWlpqsFUQPF/YBVHVlYWBgwYgNq1a6Np06aYPn06unbtioYNG750v19++UVtYp1nu66f1759exgbG+Pnn38u1mC5TZs2ISQkBDNnzlSVZWdnF/pslPQ85Ofnq3oWHBwcYGFh8cLPhZGREapWrQrgyWfoRds9Xf+UpaUlevbsiZ49eyInJwdBQUH49ttvMX78eJiZmWkUe61ateDl5YXff/8dc+bM0Xhg6YMHD7B3715MmTIFEydOVJU/bRU/z8XFBZ999hk+++wzpKSkoEGDBvj222/Rvn171TZ169ZF3bp18dVXX+HIkSPw9/fH4sWL8c0332gU2/OqV68OAHB0dCzye0zSwJ9hZWzMmDGwtLTERx99hOTk5ELrr127hjlz5gB40n0MALNnz1bbZtasWQCADh06lFlc1atXR3p6Os6ePasqS0xMLDTC/v79+4X2ffPNNwEASqWyyGO7uLjgzTffxOrVq9WSw/nz57F7927V+9SG1q1b4+uvv8b8+fPh7Oz8wu2MjY0L9QJs3LgRt2/fVit7+uND09nIijJ27FgkJCRg9erVmDVrFjw8PBASEvLC8/iUv7+/qms7ICDgpUm9atWq+Pjjj7F7927Mmzev0PqCggLMnDlT1dIr6jzMmzevUC9MSc5DdHQ0MjMzUb9+fVVd7777Ln7//Xe1memSk5Oxdu1aNGvWTNX9/d577+H48eOIiYlRbZeVlYWlS5fCw8MDtWvXBvDk7oNnmZqaonbt2hBCqO4l1zT2KVOmIDU1FR999BHy8vIKrd+9eze2b99e5L5Pe5yeP6fPf6fz8/MLdaM7OjrC1dVV9XnIyMgoVH/dunVhZGT0ys9McQQGBsLGxgbTpk0r8r77p2Mh6PXGlnoZq169OtauXYuePXvCx8cH/fr1wxtvvIGcnBwcOXIEGzduVM3bXL9+fYSEhGDp0qVIS0tDy5Ytcfz4caxevRpdunRB69atyyyuXr16YezYsejatSuGDx+uupWlVq1aaoN5pk6dioMHD6JDhw5wd3dHSkoKFi5ciCpVqqgNYnrejBkz0L59e/j5+WHQoEGqW9oUCgUmT55cZu/jeUZGRvjqq69eud3777+PqVOnYsCAAWjatCnOnTuHX375pVDCrF69OmxtbbF48WJYW1vD0tISjRs3Vl0jLa59+/Zh4cKFmDRpkuoWu6fTuE6YMAHTp0/X6HgvM3PmTFy7dg3Dhw/Hli1b8P7776NixYpISEjAxo0bcfnyZVUvxvvvv481a9ZAoVCgdu3aiImJwZ49e2Bvb692zDfffBPGxsb4/vvvkZ6eDrlcjjZt2qjGBKSnp+Pnn38G8OTWp7i4OCxatAjm5uYYN26c6jjffPMNoqKi0KxZM3z22WeoUKEClixZAqVSqXYOxo0bh3Xr1qF9+/YYPnw47OzssHr1aty4cQObN29WdQO/++67cHZ2hr+/P5ycnHDp0iXMnz8fHTp0UA128/X1BQB8+eWX6NWrF0xMTNCxY8cX9hb17NlTNcVqbGwsevfuDXd3d6SmpmLnzp3Yu3cv1q5dW+S+NjY2aNGiBaZPn47c3FxUrlwZu3fvxo0bN9S2e/jwIapUqYJu3bqhfv36sLKywp49e3DixAlVr8m+ffswdOhQdO/eHbVq1UJeXh7WrFkDY2NjBAcHF+OT8HI2NjZYtGgR+vbtiwYNGqBXr15wcHBAQkIC/vzzT/j7+2P+/Pmlrod0TJdD76XsypUr4uOPPxYeHh7C1NRUWFtbC39/fzFv3jy1iWVyc3PFlClThKenpzAxMRFVq1Z96eQzz3v+VqoX3d4ixJNJZd544w1hamoqvLy8xM8//1zolra9e/eKzp07C1dXV2FqaipcXV1F7969xZUrVwrV8fxtX3v27BH+/v7C3Nxc2NjYiI4dO75w8pnnb5l70UQZz3v2lrYXedEtbaNGjRIuLi7C3Nxc+Pv7i5iYmCJvRfv9999F7dq1RYUKFYqcfKYozx4nIyNDuLu7iwYNGojc3Fy17cLCwoSRkVGRk6+URl5enli+fLlo3ry5UCgUwsTERLi7u4sBAwao3e724MEDMWDAAFGpUiVhZWUlAgMDxeXLlwvdJiWEEMuWLRPVqlUTxsbGhSafwTO3sslkMmFnZyc6deqkNpHKU6dPnxaBgYHCyspKWFhYiNatW4sjR44U2u7p5DO2trbCzMxMNGrUqNDkM0uWLBEtWrQQ9vb2Qi6Xi+rVq4vPP/9cpKenq2339ddfi8qVKwsjI6Ni39729LPv6OgoKlSoIBwcHETHjh3F77//rtqmqM/+f//9J7p27SpsbW2FQqEQ3bt3F3fu3BEAxKRJk4QQT6YR/vzzz0X9+vVVk/DUr19fLFy4UHWc69evi4EDB4rq1aurJgZq3bq12LNnj1qcJb2l7ano6GgRGBgoFAqFMDMzE9WrVxf9+/cXJ0+eVG1TnO8Z6SeZEBqMTCIiIiK9xWvqREREEsGkTkREJBFM6kRERBLBpE5ERKRlHh4ekMlkhZbQ0FAAT+aLCA0Nhb29PaysrBAcHFzkbdGvwoFyREREWnb37l21+SDOnz+Ptm3bIjo6Gq1atcKQIUPw559/YtWqVVAoFBg6dCiMjIw0ngaZSZ2IiKicjRw5Etu3b0d8fDwyMjLg4OCAtWvXolu3bgCezKbo4+ODmJgY1QOCioPd70RERCWgVCqRkZGhthRn9r+cnBz8/PPPGDhwIGQyGU6dOoXc3Fy16Xu9vb3h5uamNsticUhyRrmeq2N1HQKR1i3vWV/XIRBpnbWZdtue5m8NLfG+YztXwpQpU9TKJk2a9MpZNLdu3Yq0tDTV7KJJSUkwNTVVPfr6KScnJyQlJWkUkySTOhERUbHISv6jYfz48QgPD1crk8vlr9xvxYoVaN++PVxdXUtc94swqRMRkeEqxZMZ5XJ5sZL4s/7991/s2bMHW7ZsUZU5OzsjJycHaWlpaq315OTklz6oqii8pk5ERIZLZlTypQRWrlwJR0dHtadw+vr6wsTEBHv37lWVxcXFISEh4ZWP8H4eW+pERETloKCgACtXrkRISAgqVPhf+lUoFBg0aBDCw8NhZ2cHGxsbDBs2DH5+fhqNfAeY1ImIyJCVovtdU3v27EFCQgIGDhxYaF1kZCSMjIwQHBwMpVKJwMBALFy4UOM6JHmfOke/kyHg6HcyBFof/d5odIn3fXz8hzKMpGywpU5ERIarHFvq5YFJnYiIDFcpbmnTR0zqRERkuCTWUpfWTxQiIiIDxpY6EREZLna/ExERSYTEut+Z1ImIyHCxpU5ERCQRbKkTERFJhMRa6tJ6N0RERAaMLXUiIjJcEmupM6kTEZHhMuI1dSIiImlgS52IiEgiOPqdiIhIIiTWUpfWuyEiIjJgbKkTEZHhYvc7ERGRREis+51JnYiIDBdb6kRERBLBljoREZFESKylLq2fKERERAaMLXUiIjJc7H4nIiKSCIl1vzOpExGR4WJLnYiISCKY1ImIiCRCYt3v0vqJQkREZMDYUiciIsPF7nciIiKJkFj3O5M6EREZLrbUiYiIJIItdSIiImmQSSypS6vfgYiISE/dvn0bH374Iezt7WFubo66devi5MmTqvVCCEycOBEuLi4wNzdHQEAA4uPjNaqDSZ2IiAyWTCYr8aKJBw8ewN/fHyYmJtixYwcuXryImTNnomLFiqptpk+fjrlz52Lx4sU4duwYLC0tERgYiOzs7GLXw+53IiIyXOXU+/7999+jatWqWLlyparM09NT9bcQArNnz8ZXX32Fzp07AwB++uknODk5YevWrejVq1ex6mFLnYiIDFZpWupKpRIZGRlqi1KpLLKebdu24e2330b37t3h6OiIt956C8uWLVOtv3HjBpKSkhAQEKAqUygUaNy4MWJiYor9fpjUiYjIYJUmqUdEREChUKgtERERRdZz/fp1LFq0CDVr1sSuXbswZMgQDB8+HKtXrwYAJCUlAQCcnJzU9nNyclKtKw52vxMRkcEqzej38ePHIzw8XK1MLpcXuW1BQQHefvttTJs2DQDw1ltv4fz581i8eDFCQkJKHMPz9KKlbmxsjJSUlELlqampMDY21kFERERELyeXy2FjY6O2vCipu7i4oHbt2mplPj4+SEhIAAA4OzsDAJKTk9W2SU5OVq0rDr1I6kKIIsuVSiVMTU3LORoiIjIU5TX63d/fH3FxcWplV65cgbu7O4Ang+acnZ2xd+9e1fqMjAwcO3YMfn5+xa5Hp93vc+fOBfDkpC5fvhxWVlaqdfn5+Th48CC8vb11FR4REUldOY1+DwsLQ9OmTTFt2jT06NEDx48fx9KlS7F06dInYchkGDlyJL755hvUrFkTnp6emDBhAlxdXdGlS5di16PTpB4ZGQngSUt98eLFal3tpqam8PDwwOLFi3UVHhERSVx5zSjXsGFD/Pbbbxg/fjymTp0KT09PzJ49G3369FFtM2bMGGRlZWHw4MFIS0tDs2bNsHPnTpiZmRW7Hpl4Ud93OWrdujW2bNmidhN+afRcHVsmxyHSZ8t71td1CERaZ22m3avEFT/8pcT7Pvi5z6s3Kmd6Mfo9Ojpa1yEQEZEBktrc73qR1PPz87Fq1Srs3bsXKSkpKCgoUFu/b98+HUVGRET0+tCLpD5ixAisWrUKHTp0wBtvvCG5X05ERKSfpJZv9CKpr1+/Hhs2bMB7772n61CIiMiQSCun60dSNzU1RY0aNXQdBhERGRiptdT1YvKZUaNGYc6cOS+chIaIiEgbymvymfKiFy31v//+G9HR0dixYwfq1KkDExMTtfVbtmzRUWRERCRl+pqcS0ovkrqtrS26du2q6zCIiIhea3qR1J99aDwREVG5kVZDXT+SOhERkS6w+11LNm3ahA0bNiAhIQE5OTlq606fPq2jqIiISMqkltT1YvT73LlzMWDAADg5OSE2NhaNGjWCvb09rl+/jvbt2+s6PCIikiipjX7Xi6S+cOFCLF26FPPmzYOpqSnGjBmDqKgoDB8+HOnp6boOj4iIJIpJXQsSEhLQtGlTAIC5uTkePnwIAOjbty/WrVuny9CIiIheG3qR1J2dnXH//n0AgJubG44ePQoAuHHjBiekISIi7ZGVYtFDepHU27Rpg23btgEABgwYgLCwMLRt2xY9e/bk/etERKQ1Uut+14vR70uXLlU9bjU0NBT29vY4cuQIOnXqhE8++UTH0RERkVTpa3IuKb1I6kZGRjAy+l+nQa9evdCrVy8dRkRERIaASV1L0tLScPz4caSkpKha7U/169dPR1ERERG9PvQiqf/xxx/o06cPMjMzYWNjo/bLSSaTMakTEZF2SKuhrh9JfdSoURg4cCCmTZsGCwsLXYdDxdD5DSd84OuKvy6mYPWJ2wAAEyMZ+jasjKYeFWFiLMM/dx5ixdFbSM/O03G0RCW3acM6bNqwHol3nnzOq1WvgY8++Qz+zVroODIqC1LrfteL0e+3b9/G8OHDmdBfE9XtLRBQyx7/3n+sVt6vUWX4VlEg8sANTN4Zj4rmJhjV2lNHURKVDUdHZwwdEY416zbhp7Ub8XajJhg1YiiuXY3XdWhUBqQ2+l0vknpgYCBOnjyp6zCoGOQVjDC0uTuWxtxCZs7/WuDmJkZoU8MeP528jQtJmbhx/zEWHf4XXo5WqFmJP9bo9dWiVWs0a94Sbu4ecPfwROiwkbCwsMC5s//oOjQqA1JL6nrR/d6hQwd8/vnnuHjxIurWrQsTExO19Z06ddJRZPS8QY2rIPZ2Bs4lPkTXek6q8mr2FqhgbIRzdx6qyu5kKHE3Mwc1HS0Rf++RLsIlKlP5+fnYs3snHj9+hHr139R1OFQG9DU5l5ReJPWPP/4YADB16tRC62QyGfLz88s7JCpCUw9beNpb4IvtcYXW2ZqbIDe/AI9y1f9bpWfnwtbMpND2RK+Tq/FXMKBvb+TkKGFuYYEZkfNQrXoNXYdFVIheJPXnb2HThFKphFKpVCvLz82BsYlpacOiZ9hbmCCkURV8G3UVuQWcupcMi7uHB9Zu2ILMzEzsjdqFyRPGY+mKn5jYpUBaDXX9SOqlERERgSlTpqiV1e48GG90/VRHEUmTp70FbM1N8N373qoyYyMZfJysEOjtgGlRV2FibAQLE2O11rrCzARp2bm6CJmozJiYmKKqmzsAwKd2HVy8cA7rflmDLydOecWepO/Y/a4Fc+fOLbJcJpPBzMwMNWrUQIsWLWBsbFxom/HjxyM8PFytbOCGS1qJ05CdT3yI0b+rn9ch/m64na7EtvPJuJeVg7z8ArzhYoXjCU8el+tiI4eDlSniU7J0ETKR1hQUCOTm5ug6DCoDTOpaEBkZibt37+LRo0eoWLEiAODBgwewsLCAlZUVUlJSUK1aNURHR6Nq1apq+8rlcsjlcrUydr2Xvey8AtxKyy5UlqnMU5Xvu5qKfg2rICsnH49y8jGgcRXEpWRykBy91ubPmYWmzZrD2dkVjx5lYedf23Hq5HHMW7RM16FRGZBYTtePW9qmTZuGhg0bIj4+HqmpqUhNTcWVK1fQuHFjzJkzBwkJCXB2dkZYWJiuQ6WX+On4bZz+Lx3hrTwxuV1NpD/Ow8zoG7oOi6hU7t9PxaSvxiG4c3sM+XgALl44h3mLlqGJn7+uQ6MyILVb2mRCDx5YXr16dWzevBlvvvmmWnlsbCyCg4Nx/fp1HDlyBMHBwUhMTHzl8XqujtVSpET6Y3nP+roOgUjrrM202/as+fnOEu8bP6NdGUZSNvSi+z0xMRF5eYWnEs3Ly0NSUhIAwNXVFQ8fPiy0DRERUUnpaYO7xPSi+71169b45JNPEBv7vxZ2bGwshgwZgjZt2gAAzp07B09PTjlKRERlR2rd73qR1FesWAE7Ozv4+vqqBr69/fbbsLOzw4oVKwAAVlZWmDlzpo4jJSIiKZHJSr7oI71I6s7OzoiKisLFixexceNGbNy4ERcvXsTu3bvh5PRkKtLWrVvj3Xff1XGkREQkJUZGshIvmpg8eXKhlr639//m/cjOzkZoaCjs7e1hZWWF4OBgJCcna/x+9OKa+lPe3t5qb5KIiEibyrPFXadOHezZs0f1ukKF/6XgsLAw/Pnnn9i4cSMUCgWGDh2KoKAgHD58WKM6dJbUw8PD8fXXX8PS0rLQ5DHPmzVrVjlFRUREpB0VKlSAs7NzofL09HSsWLECa9euVY0jW7lyJXx8fHD06FE0adKk+HWUWbQaio2NRW5ururvF9HXwQhERPT6K02OKerZI0VNiPZUfHw8XF1dYWZmBj8/P0RERMDNzQ2nTp1Cbm4uAgICVNt6e3vDzc0NMTExr0dSj46OLvJvIiKi8lKadmNRzx6ZNGkSJk+eXGjbxo0bY9WqVfDy8kJiYiKmTJmC5s2b4/z580hKSoKpqSlsbW3V9nFyclLd1l1cenVNnYiIqDyVpqVe1LNHXtRKb9++vervevXqoXHjxnB3d8eGDRtgbm5e4hiep7OkHhQUVOxtt2zZosVIiIjIUJUmqb+sq/1VbG1tUatWLVy9ehVt27ZFTk4O0tLS1FrrycnJRV6DfxmdJXWFQqGrqomIiADo7n7zzMxMXLt2DX379oWvry9MTEywd+9eBAcHAwDi4uKQkJAAPz8/jY6rs6S+cuVKXVVNRERUrkaPHo2OHTvC3d0dd+7cwaRJk2BsbIzevXtDoVBg0KBBCA8Ph52dHWxsbDBs2DD4+flpNEgO4DV1IiIyYOV1h9V///2H3r17IzU1FQ4ODmjWrBmOHj0KBwcHAE8eQW5kZITg4GAolUoEBgZi4cKFGtejN0l906ZN2LBhAxISEpCTk6O27vTp0zqKioiIpKy8ut/Xr1//0vVmZmZYsGABFixYUKp69GKa2Llz52LAgAFwcnJCbGwsGjVqBHt7e1y/fl1txCAREVFZ4gNdtGDhwoVYunQp5s2bB1NTU4wZMwZRUVEYPnw40tPTdR0eERFJFB/oogUJCQlo2rQpAMDc3Fz13PS+ffti3bp1ugyNiIgkjC11LXB2dsb9+/cBAG5ubjh69CgA4MaNGxBC6DI0IiKi14ZeJPU2bdpg27ZtAIABAwYgLCwMbdu2Rc+ePdG1a1cdR0dERFIlte53vRj9vnTpUhQUFAAAQkNDUalSJRw+fBidOnXCp59+quPoiIhIqvS1G72k9CKpGxkZIScnB6dPn0ZKSgrMzc1VT6vZuXMnOnbsqOMIiYhIiiSW0/Ujqe/cuRN9+/ZFampqoXUymQz5+fk6iIqIiKROai11vbimPmzYMPTo0QOJiYkoKChQW5jQiYhIW6R2TV0vknpycjLCw8Ph5OSk61CIiIheW3qR1Lt164b9+/frOgwiIjIwUrtPXS+uqc+fPx/du3fHoUOHULduXZiYmKitHz58uI4iIyIiKdPT3FxiepHU161bh927d8PMzAz79+9X+wUkk8mY1ImISCv0tcVdUnqR1L/88ktMmTIF48aNg5GRXlwRICIiA8CkrgU5OTno2bMnEzoREZUrieV0/RgoFxISgl9//VXXYRAREb3W9KKlnp+fj+nTp2PXrl2oV69eoYFys2bN0lFkREQkZex+14Jz587hrbfeAgCcP39ebZ3UTjgREekPqaUYvUjq0dHRug6BiIgMkNQajnqR1ImIiHRBYjmdSZ2IiAyXkcSyul6MficiIqLSY0udiIgMlsQa6kzqRERkuDhQjoiISCKMpJXTmdSJiMhwsaVOREQkERLL6Rz9TkREJBVsqRMRkcGSQVpNdSZ1IiIyWBwoR0REJBEcKEdERCQREsvpTOpERGS4OPc7ERER6SUmdSIiMlgyWcmXkvruu+8gk8kwcuRIVVl2djZCQ0Nhb28PKysrBAcHIzk5WeNjM6kTEZHBkslkJV5K4sSJE1iyZAnq1aunVh4WFoY//vgDGzduxIEDB3Dnzh0EBQVpfHwmdSIiMljl2VLPzMxEnz59sGzZMlSsWFFVnp6ejhUrVmDWrFlo06YNfH19sXLlShw5cgRHjx7VqA4mdSIiMlhGMlmJF6VSiYyMDLVFqVS+sK7Q0FB06NABAQEBauWnTp1Cbm6uWrm3tzfc3NwQExOj2fvR7O0TERFJh6wUS0REBBQKhdoSERFRZD3r16/H6dOni1yflJQEU1NT2NraqpU7OTkhKSlJo/dTrFvatm3bVuwDdurUSaMAiIiIXkfjx49HeHi4WplcLi+03a1btzBixAhERUXBzMxMqzEVK6l36dKlWAeTyWTIz88vTTxERETlpjQzysnl8iKT+PNOnTqFlJQUNGjQQFWWn5+PgwcPYv78+di1axdycnKQlpam1lpPTk6Gs7OzRjEVK6kXFBRodFAiIqLXQXnM/f7OO+/g3LlzamUDBgyAt7c3xo4di6pVq8LExAR79+5FcHAwACAuLg4JCQnw8/PTqC7OKEdERAarPOZ+t7a2xhtvvKFWZmlpCXt7e1X5oEGDEB4eDjs7O9jY2GDYsGHw8/NDkyZNNKqrREk9KysLBw4cQEJCAnJyctTWDR8+vCSHJCIiKnf6MktsZGQkjIyMEBwcDKVSicDAQCxcuFDj48iEEEKTHWJjY/Hee+/h0aNHyMrKgp2dHe7duwcLCws4Ojri+vXrGgdR1nqujtV1CERat7xnfV2HQKR11mbavUmr39qzJd73pw/qvXqjcqbx2QoLC0PHjh3x4MEDmJub4+jRo/j333/h6+uLH374QRsxEhERUTFonNTPnDmDUaNGwcjICMbGxlAqlahatSqmT5+OL774QhsxEhERaYWRrOSLPtI4qZuYmMDI6Mlujo6OSEhIAAAoFArcunWrbKMjIiLSovKe+13bNB4o99Zbb+HEiROoWbMmWrZsiYkTJ+LevXtYs2ZNodF9RERE+kw/U3PJadxSnzZtGlxcXAAA3377LSpWrIghQ4bg7t27WLp0aZkHSEREpC2lmftdH2ncUn/77bdVfzs6OmLnzp1lGhARERGVDCefISIig6WnDe4S0zipe3p6vnSAgD7cp05ERFQc+jrgraQ0TuojR45Ue52bm4vY2Fjs3LkTn3/+eVnFRUREpHUSy+maJ/URI0YUWb5gwQKcPHmy1AERERGVF30d8FZSZTb/Xvv27bF58+ayOhwREZHWyWQlX/RRmSX1TZs2wc7OrqwOR0RERBoq0eQzzw4sEEIgKSkJd+/eLdETZYiIiHTF4AfKde7cWe0kGBkZwcHBAa1atYK3t3eZBldSq/u8pesQiLSuYsOhug6BSOsex87X6vG1+wy48qdxUp88ebIWwiAiIip/Umupa/wjxdjYGCkpKYXKU1NTYWxsXCZBERERlQepPaVN45a6EKLIcqVSCVNT01IHREREVF70NTmXVLGT+ty5cwE86apYvnw5rKysVOvy8/Nx8OBBvbmmTkREZIiKndQjIyMBPGmpL168WK2r3dTUFB4eHli8eHHZR0hERKQlUrumXuykfuPGDQBA69atsWXLFlSsWFFrQREREZUHg+1+fyo6OlobcRAREZU7iTXUNR/9HhwcjO+//75Q+fTp09G9e/cyCYqIiKg8GMlkJV70kcZJ/eDBg3jvvfcKlbdv3x4HDx4sk6CIiIjKg1EpFn2kcVyZmZlF3rpmYmKCjIyMMgmKiIiINKdxUq9bty5+/fXXQuXr169H7dq1yyQoIiKi8iC1p7RpPFBuwoQJCAoKwrVr19CmTRsAwN69e7F27Vps2rSpzAMkIiLSFn29Nl5SGif1jh07YuvWrZg2bRo2bdoEc3Nz1K9fH/v27eOjV4mI6LUisZyueVIHgA4dOqBDhw4AgIyMDKxbtw6jR4/GqVOnkJ+fX6YBEhERaYvU7lMv8QC+gwcPIiQkBK6urpg5cybatGmDo0ePlmVsREREWiW1W9o0aqknJSVh1apVWLFiBTIyMtCjRw8olUps3bqVg+SIiIh0rNgt9Y4dO8LLywtnz57F7NmzcefOHcybN0+bsREREWmVwY5+37FjB4YPH44hQ4agZs2a2oyJiIioXBjsNfW///4bDx8+hK+vLxo3boz58+fj3r172oyNiIhIq2Sl+EcfFTupN2nSBMuWLUNiYiI++eQTrF+/Hq6urigoKEBUVBQePnyozTiJiIjKnJGs5IsmFi1ahHr16sHGxgY2Njbw8/PDjh07VOuzs7MRGhoKe3t7WFlZITg4GMnJyZq/H013sLS0xMCBA/H333/j3LlzGDVqFL777js4OjqiU6dOGgdARESkK+WV1KtUqYLvvvsOp06dwsmTJ9GmTRt07twZFy5cAACEhYXhjz/+wMaNG3HgwAHcuXMHQUFBGr8fmRBCaLzXc/Lz8/HHH3/gxx9/xLZt20p7uFLLztN1BETaV7HhUF2HQKR1j2Pna/X406OvlXjfMa2rl6puOzs7zJgxA926dYODgwPWrl2Lbt26AQAuX74MHx8fxMTEoEmTJsU+Zokmn3mesbExunTpgi5dupTF4YiIiMqFrBTD2JVKJZRKpVqZXC6HXC5/6X75+fnYuHEjsrKy4Ofnh1OnTiE3NxcBAQGqbby9veHm5qZxUtfXp8cRERFpXWm63yMiIqBQKNSWiIiIF9Z17tw5WFlZQS6X49NPP8Vvv/2G2rVrIykpCaamprC1tVXb3snJCUlJSRq9nzJpqRMREb2OSnO/+fjx4xEeHq5W9rJWupeXF86cOYP09HRs2rQJISEhOHDgQMkDKAKTOhERGazSTPdanK72Z5mamqJGjRoAAF9fX5w4cQJz5sxBz549kZOTg7S0NLXWenJyMpydnTWKid3vRERksMpr9HtRCgoKoFQq4evrCxMTE+zdu1e1Li4uDgkJCfDz89PomGypExERadn48ePRvn17uLm54eHDh1i7di3279+PXbt2QaFQYNCgQQgPD4ednR1sbGwwbNgw+Pn5aTRIDmBSJyIiA1Zec7inpKSgX79+SExMhEKhQL169bBr1y60bdsWABAZGQkjIyMEBwdDqVQiMDAQCxcu1LieMrlPXd/wPnUyBLxPnQyBtu9TX3D4Zon3DfX3KLM4ygpb6kREZLD09WlrJcWkTkREBktqT2ljUiciIoNVmlva9BFvaSMiIpIIttSJiMhgSayhzqRORESGS2rd70zqRERksCSW05nUiYjIcEltYBmTOhERGazSPE9dH0ntRwoREZHBYkudiIgMlrTa6UzqRERkwDj6nYiISCKkldKZ1ImIyIBJrKHOpE5ERIaLo9+JiIhIL7GlTkREBktqLVsmdSIiMlhS635nUiciIoMlrZTOpE5ERAaMLXUiIiKJkNo1dam9HyIiIoPFljoRERksdr8TERFJhLRSOpM6EREZMIk11JnUiYjIcBlJrK2uN0k9Pj4e0dHRSElJQUFBgdq6iRMn6igqIiKSMrbUtWDZsmUYMmQIKlWqBGdnZ7WBCzKZjEmdiIioGPQiqX/zzTf49ttvMXbsWF2HQkREBkTG7vey9+DBA3Tv3l3XYRARkYGRWve7Xkw+0717d+zevVvXYRARkYExgqzEiz7Si5Z6jRo1MGHCBBw9ehR169aFiYmJ2vrhw4frKDIiIpIyqbXUZUIIoesgPD09X7hOJpPh+vXrGh0vO6+0ERHpv4oNh+o6BCKtexw7X6vH333pbon3fdfHoQwjKRt60VK/ceOGrkMgIiJ67enFNXUiIiJdkJXiH01ERESgYcOGsLa2hqOjI7p06YK4uDi1bbKzsxEaGgp7e3tYWVkhODgYycnJGtWjFy318PDwIstlMhnMzMxQo0YNdO7cGXZ2duUcGRERSZlROV1TP3DgAEJDQ9GwYUPk5eXhiy++wLvvvouLFy/C0tISABAWFoY///wTGzduhEKhwNChQxEUFITDhw8Xux69uKbeunVrnD59Gvn5+fDy8gIAXLlyBcbGxvD29kZcXBxkMhn+/vtv1K5d+5XH4zV1MgS8pk6GQNvX1PddTi3xvm287Uu87927d+Ho6IgDBw6gRYsWSE9Ph4ODA9auXYtu3boBAC5fvgwfHx/ExMSgSZMmxTquXnS/d+7cGQEBAbhz5w5OnTqFU6dO4b///kPbtm3Ru3dv3L59Gy1atEBYWJiuQyUiIgmRyUq+KJVKZGRkqC1KpbJY9aanpwOAqgf61KlTyM3NRUBAgGobb29vuLm5ISYmptjvRy+S+owZM/D111/DxsZGVaZQKDB58mRMnz4dFhYWmDhxIk6dOqXDKImIiP4nIiICCoVCbYmIiHjlfgUFBRg5ciT8/f3xxhtvAACSkpJgamoKW1tbtW2dnJyQlJRU7Jj04pp6eno6UlJSCnWt3717FxkZGQAAW1tb5OTk6CI8IiKSqNJMEzt+/PhCY8Lkcvkr9wsNDcX58+fx999/l7juF9GLpN65c2cMHDgQM2fORMOGDQEAJ06cwOjRo9GlSxcAwPHjx1GrVi0dRknPO3XyBFb9uAKXLp7H3bt3ETl3Adq8E/DqHYn02OU/p8DdtfC10sW/HkTYdxsgN62A78KD0D3QF3LTCtgTcwkjpv2KlPsPdRAtlVZpBsrJ5fJiJfFnDR06FNu3b8fBgwdRpUoVVbmzszNycnKQlpam1lpPTk6Gs7NzsY+vF0l9yZIlCAsLQ69evZCX92SUW4UKFRASEoLIyEgAT64tLF++XJdh0nMeP34ELy8vdAkKRvgIDtoiaWj24QwYP/N/+to1XPHX4mHYEhULAJg+Ohjtm9VBnzErkJH5GJHjemD9zI/QZkCkrkKmUiivB7oIITBs2DD89ttv2L9/f6FJ13x9fWFiYoK9e/ciODgYABAXF4eEhAT4+fkVux69SOpWVlZYtmwZIiMjVbPHVatWDVZWVqpt3nzzTR1FRy/SrHlLNGveUtdhEJWpew8y1V6PHvAGriXcxaFT8bCxMkP/Ln7o/8UqHDhxBQAweNLP+Oe3CWhU1wPHz93UQcRUGuU1TWxoaCjWrl2L33//HdbW1qrr5AqFAubm5lAoFBg0aBDCw8NhZ2cHGxsbDBs2DH5+fsUe+Q7oSVJ/ysrKCvXq1dN1GEREAACTCsbo9V5DzP15HwDgLR83mJpUwL6j/5s05MrNZCQk3kfjep5M6q+h8pr6fdGiRQCAVq1aqZWvXLkS/fv3BwBERkbCyMgIwcHBUCqVCAwMxMKFCzWqR2dJPSgoCKtWrYKNjQ2CgoJeuu2WLVvKKSoiov/p1LoebK3N8fMfxwAAzvY2UObkIj3zsdp2KakZcLK3KeoQRACedL+/ipmZGRYsWIAFCxaUuB6dJXWFQgHZ//d7KBSKEh9HqVQWui9QGGs+eIGI6HkhXZpi1+GLSLybrutQSEuMJPaYNp0l9ZUrVxb5t6YiIiIwZcoUtbIvJ0zCVxMnl/iYRERuLhXRprEXeo1epipLSs2A3NQECitztda6o70NklMzdBEmlZK0UrqeXVMviaLuExTGbKUTUen07eSHlPsPsePQBVVZ7KUE5OTmoXVjL2zdewYAUNPdEW4udjh2lk+bfC1JLKvrRVJPTk7G6NGjsXfvXqSkpBS69pCfn//CfYu6T5Bzv5ePR1lZSEhIUL2+/d9/uHzpEhQKBVxcXXUYGVHpyGQy9OvcBL9sP4b8/AJVeUZmNlZtjcH3o4JwPz0LD7OyMWtsdxz95zoHyb2myuuWtvKiF0m9f//+SEhIwIQJE+Di4qK61k767cKF8/hoQD/V6x+mP5kesVPnrvh62ne6Couo1No09oKbix1Wbz1aaN2YHzajoEBg3Q8fPZl85sgljIj4VQdRUlmQWrrRi6e0WVtb49ChQ2V2Lzpb6mQI+JQ2MgTafkrb8eslHwTZqFrJB3lri1601KtWrVqs4f5ERERlSWINdf14Stvs2bMxbtw43Lx5U9ehEBGRIZGVYtFDetFS79mzJx49eoTq1avDwsICJiYmauvv37+vo8iIiEjKOFBOC2bPnq3rEIiIyABJbaCcXiT1kJAQXYdAREQGSGI5XT+uqQPAtWvX8NVXX6F3795ISUkBAOzYsQMXLlx4xZ5EREQE6ElSP3DgAOrWrYtjx45hy5YtyMx88ujDf/75B5MmTdJxdEREJFkSGyinF0l93Lhx+OabbxAVFQVTU1NVeZs2bXD0aOHJH4iIiMqCrBT/6CO9uKZ+7tw5rF27tlC5o6Mj7t27p4OIiIjIEEhtoJxetNRtbW2RmJhYqDw2NhaVK1fWQURERGQIJNb7rh9JvVevXhg7diySkpIgk8lQUFCAw4cPY/To0ejXr9+rD0BERFQSEsvqepHUp02bBm9vb1StWhWZmZmoXbs2mjdvjqZNm+Krr77SdXhERESvBb14oMtTt27dwrlz55CVlYW33noLNWrUKNFx+EAXMgR8oAsZAm0/0OXsrcwS71uvqlUZRlI29GKgHACsWLECkZGRiI+PBwDUrFkTI0eOxEcffaTjyIiISKqkNlBOL5L6xIkTMWvWLAwbNgx+fn4AgJiYGISFhSEhIQFTp07VcYRERCRFEsvp+tH97uDggLlz56J3795q5evWrcOwYcM0vq2N3e9kCNj9ToZA293v52+XvPv9jcrsfi9Sbm4u3n777ULlvr6+yMtjhiYiIu3Q10lkSkovRr/37dsXixYtKlS+dOlS9OnTRwcRERERvX501lIPDw9X/S2TybB8+XLs3r0bTZo0AQAcO3YMCQkJvE+diIi0hgPlykhsbKzaa19fXwBPntYGAJUqVUKlSpX4lDYiItIaieV03SX16OhoXVVNRET0hMSyul4MlCMiItIFqQ2UY1InIiKDJbVr6nox+p2IiIhKjy11IiIyWBJrqDOpExGRAZNYVmdSJyIig8WBckRERBLBgXJEREQSISvFoomDBw+iY8eOcHV1hUwmw9atW9XWCyEwceJEuLi4wNzcHAEBAapHkWuCSZ2IiEjLsrKyUL9+fSxYsKDI9dOnT8fcuXOxePFiHDt2DJaWlggMDER2drZG9bD7nYiIDFc5db+3b98e7du3L3KdEAKzZ8/GV199hc6dOwMAfvrpJzg5OWHr1q3o1atXsethS52IiAyWrBT/KJVKZGRkqC1KpVLjGG7cuIGkpCQEBASoyhQKBRo3boyYmBiNjsWkTkREBksmK/kSEREBhUKhtkRERGgcQ1JSEgDAyclJrdzJyUm1rrjY/U5ERAarNL3v48ePV3uMOADI5fLSBVRKTOpERGS4SpHV5XJ5mSRxZ2dnAEBycjJcXFxU5cnJyXjzzTc1Oha734mIiHTI09MTzs7O2Lt3r6osIyMDx44dg5+fn0bHYkudiIgMVnnNKJeZmYmrV6+qXt+4cQNnzpyBnZ0d3NzcMHLkSHzzzTeoWbMmPD09MWHCBLi6uqJLly4a1cOkTkREBqu8ZpQ7efIkWrdurXr99Fp8SEgIVq1ahTFjxiArKwuDBw9GWloamjVrhp07d8LMzEyjemRCCFGmkeuB7DxdR0CkfRUbDtV1CERa9zh2vlaPf+u+5regPVXVTreD4orCljoRERksqc39zqROREQGTFpZnaPfiYiIJIItdSIiMljsficiIpIIieV0JnUiIjJcbKkTERFJRHlNPlNemNSJiMhwSSunc/Q7ERGRVLClTkREBktiDXUmdSIiMlwcKEdERCQRHChHREQkFdLK6UzqRERkuCSW0zn6nYiISCrYUiciIoPFgXJEREQSwYFyREREEiG1ljqvqRMREUkEW+pERGSw2FInIiIivcSWOhERGSwOlCMiIpIIqXW/M6kTEZHBklhOZ1InIiIDJrGszoFyREREEsGWOhERGSwOlCMiIpIIDpQjIiKSCInldCZ1IiIyYBLL6kzqRERksKR2TZ2j34mIiCSCLXUiIjJYUhsoJxNCCF0HQa83pVKJiIgIjB8/HnK5XNfhEGkFP+f0OmBSp1LLyMiAQqFAeno6bGxsdB0OkVbwc06vA15TJyIikggmdSIiIolgUiciIpIIJnUqNblcjkmTJnHwEEkaP+f0OuBAOSIiIolgS52IiEgimNSJiIgkgkmdiIhIIpjUqZD+/fujS5cuqtetWrXCyJEjdRYPkabK4zP7/PeESB9w7nd6pS1btsDExETXYRTJw8MDI0eO5I8OKndz5swBxxmTvmFSp1eys7PTdQhEekehUOg6BKJC2P3+mmvVqhWGDRuGkSNHomLFinBycsKyZcuQlZWFAQMGwNraGjVq1MCOHTsAAPn5+Rg0aBA8PT1hbm4OLy8vzJkz55V1PNsSTkxMRIcOHWBubg5PT0+sXbsWHh4emD17tmobmUyG5cuXo2vXrrCwsEDNmjWxbds21frixPG0e/OHH36Ai4sL7O3tERoaitzcXFVc//77L8LCwiCTySCT2uOWqFTy8vIwdOhQKBQKVKpUCRMmTFC1rJVKJUaPHo3KlSvD0tISjRs3xv79+1X7rlq1Cra2tti1axd8fHxgZWWFdu3aITExUbXN893vDx8+RJ8+fWBpaQkXFxdERkYW+u54eHhg2rRpGDhwIKytreHm5oalS5dq+1SQAWFSl4DVq1ejUqVKOH78OIYNG4YhQ4age/fuaNq0KU6fPo13330Xffv2xaNHj1BQUIAqVapg48aNuHjxIiZOnIgvvvgCGzZsKHZ9/fr1w507d7B//35s3rwZS5cuRUpKSqHtpkyZgh49euDs2bN477330KdPH9y/fx8Aih1HdHQ0rl27hujoaKxevRqrVq3CqlWrADy5LFClShVMnToViYmJav/DJVq9ejUqVKiA48ePY86cOZg1axaWL18OABg6dChiYmKwfv16nD17Ft27d0e7du0QHx+v2v/Ro0f44YcfsGbNGhw8eBAJCQkYPXr0C+sLDw/H4cOHsW3bNkRFReHQoUM4ffp0oe1mzpyJt99+G7Gxsfjss88wZMgQxMXFlf0JIMMk6LXWsmVL0axZM9XrvLw8YWlpKfr27asqS0xMFABETExMkccIDQ0VwcHBqtchISGic+fOanWMGDFCCCHEpUuXBABx4sQJ1fr4+HgBQERGRqrKAIivvvpK9TozM1MAEDt27HjheykqDnd3d5GXl6cq6969u+jZs6fqtbu7u1q9REI8+cz6+PiIgoICVdnYsWOFj4+P+Pfff4WxsbG4ffu22j7vvPOOGD9+vBBCiJUrVwoA4urVq6r1CxYsEE5OTqrXz35PMjIyhImJidi4caNqfVpamrCwsFB9d4R48nn98MMPVa8LCgqEo6OjWLRoUZm8byJeU5eAevXqqf42NjaGvb096tatqypzcnICAFVresGCBfjxxx+RkJCAx48fIycnB2+++Wax6oqLi0OFChXQoEEDVVmNGjVQsWLFl8ZlaWkJGxsbtRZ9ceKoU6cOjI2NVa9dXFxw7ty5YsVKhq1JkyZql2T8/Pwwc+ZMnDt3Dvn5+ahVq5ba9kqlEvb29qrXFhYWqF69uuq1i4tLkT1SAHD9+nXk5uaiUaNGqjKFQgEvL69C2z77vZDJZHB2dn7hcYk0xaQuAc+PTJfJZGplT//HVlBQgPXr12P06NGYOXMm/Pz8YG1tjRkzZuDYsWPlEldBQQEAFDuOlx2DqCQyMzNhbGyMU6dOqf1gBAArKyvV30V99kQZjHbnZ5q0iUndwBw+fBhNmzbFZ599piq7du1asff38vJCXl4eYmNj4evrCwC4evUqHjx4UK5xPGVqaor8/HyN9yPpe/4H4tGjR1GzZk289dZbyM/PR0pKCpo3b14mdVWrVg0mJiY4ceIE3NzcAADp6em4cuUKWrRoUSZ1EBUHB8oZmJo1a+LkyZPYtWsXrly5ggkTJuDEiRPF3t/b2xsBAQEYPHgwjh8/jtjYWAwePBjm5uYajT4vbRxPeXh44ODBg7h9+zbu3bun8f4kXQkJCQgPD0dcXBzWrVuHefPmYcSIEahVqxb69OmDfv36YcuWLbhx4waOHz+OiIgI/PnnnyWqy9raGiEhIfj8888RHR2NCxcuYNCgQTAyMuJdGVSumNQNzCeffIKgoCD07NkTjRs3RmpqqlpruTh++uknODk5oUWLFujatSs+/vhjWFtbw8zMrFzjAICpU6fi5s2bqF69OhwcHDTen6SrX79+ePz4MRo1aoTQ0FCMGDECgwcPBgCsXLkS/fr1w6hRo+Dl5YUuXbqotbJLYtasWfDz88P777+PgIAA+Pv7w8fHR6PvBVFp8dGrVGr//fcfqlatij179uCdd97RdThEeiErKwuVK1fGzJkzMWjQIF2HQwaC19RJY/v27UNmZibq1q2LxMREjBkzBh4eHrx2SAYtNjYWly9fRqNGjZCeno6pU6cCADp37qzjyMiQMKmTxnJzc/HFF1/g+vXrsLa2RtOmTfHLL7/o7fzwROXlhx9+QFxcHExNTeHr64tDhw6hUqVKug6LDAi734mIiCSCA+WIiIgkgkmdiIhIIpjUiYiIJIJJnYiISCKY1ImIiCSCSZ3oNdC/f3906dJF9bpVq1YYOXJkucexf/9+yGQypKWllXvdRPRqTOpEpdC/f3/IZDLIZDKYmpqiRo0amDp1KvLy8rRa75YtW/D1118Xa1smYiLDwclniEqpXbt2WLlyJZRKJf766y+EhobCxMQE48ePV9suJycHpqamZVKnnZ1dmRyHiKSFLXWiUpLL5XB2doa7uzuGDBmCgIAAbNu2TdVl/u2338LV1RVeXl4AgFu3bqFHjx6wtbWFnZ0dOnfujJs3b6qOl5+fj/DwcNja2sLe3h5jxowp9Bzv57vflUolxo4di6pVq0Iul6NGjRpYsWIFbt68idatWwMAKlasCJlMhv79+wMACgoKEBERAU9PT5ibm6N+/frYtGmTWj1//fUXatWqBXNzc7Ru3VotTiLSP0zqRGXM3NwcOTk5AIC9e/ciLi4OUVFR2L59O3JzcxEYGAhra2scOnQIhw8fhpWVFdq1a6faZ+bMmVi1ahV+/PFH/P3337h//z5+++23l9bZr18/rFu3DnPnzsWlS5ewZMkSWFlZoWrVqti8eTMAIC4uDomJiZgzZw4AICIiAj/99BMWL16MCxcuICwsDB9++CEOHDgA4MmPj6CgIHTs2BFnzpzBRx99hHHjxmnrtBFRWRBEVGIhISGic+fOQgghCgoKRFRUlJDL5WL06NEiJCREODk5CaVSqdp+zZo1wsvLSxQUFKjKlEqlMDc3F7t27RJCCOHi4iKmT5+uWp+bmyuqVKmiqkcIIVq2bClGjBghhBAiLi5OABBRUVFFxhgdHS0AiAcPHqjKsrOzhYWFhThy5IjatoMGDRK9e/cWQggxfvx4Ubt2bbX1Y8eOLXQsItIfvKZOVErbt2+HlZUVcnNzUVBQgA8++ACTJ09GaGgo6tatq3Yd/Z9//sHVq1dhbW2tdozs7Gxcu3YN6enpSExMROPGjVXrKlSogLfffrtQF/xTZ86cgbGxMVq2bFnsmK9evYpHjx6hbdu2auU5OTl46623AACXLl1SiwMA/Pz8il0HEZU/JnWiUmrdujUWLVoEU1NTuLq6okKF/32tLC0t1bbNzMyEr68vfvnll0LHcXBwKFH95ubmGu+TmZkJAPjzzz9RuXJltXVyubxEcRCR7jGpE5WSpaUlatSoUaxtGzRogF9//RWOjo6wsbEpchsXFxccO3ZM9Xz6vLw8nDp1Cg0aNChy+7p166KgoAAHDhxAQEBAofVPewry8/NVZbVr14ZcLkdCQsILW/g+Pj7Ytm2bWtnRo0df/SaJSGc4UI6oHPXp0weVKlVC586dcejQIdy4cQP79+/H8OHD8d9//wEARowYge+++w5bt27F5cuX8dlnn730HnMPDw+EhIRg4MCB2Lp1q+qYGzZsAAC4u7tDJpNh+/btuHv3LjIzM2FtbY3Ro0cjLCwMq1evxrVr13D69GnMmzcPq1evBgB8+umniI+Px+eff464uDisXbsWq1at0vYpIqJSYFInKkcWFhY4ePAg3NzcEBQUBB8fHwwaNAjZ2dmqlvuoUaPQt29fhISEwM/PD9bW1ujatetLj7to0SJ069YNn332Gby9vfHxxx8jKysLAFC5cmVMmTIF48aNg5OTE4YOHQoA+PrrrzFhwgRERETAx8cH7dq1w59//glPT08AgJubGzZv3oytW7eifv36WLx4MaZNm6bFs0NEpSUTLxp9Q0RERK8VttSJiIgkgkmdiIhIIpjUiYiIJIJJnYiISCKY1ImIiCSCSZ2IiEgimNSJiIgkgkmdiIhIIpjUiYiIJIJJnYiISCKY1ImIiCTi/wDuvvlnYyWhTAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**:\n",
        "\n",
        "- CatBoost Classifier: Gradient boosting algorithm that handles categorical data efficiently (though the Breast Cancer dataset is numeric).\n",
        "\n",
        "- Confusion Matrix: Shows counts of True Positives, True Negatives, False Positives, and False Negatives.\n",
        "\n",
        "- Seaborn Heatmap: Makes it visually appealing and easy to interpret."
      ],
      "metadata": {
        "id": "Rsu3PYbaTV9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10: You're working for a FinTech company trying to predict loan default using customer demographics and transaction behavior. The dataset is imbalanced, contains missing values, and has both numeric and categorical features. Describe your step-by-step data science pipeline using boosting techniques:**\n",
        "\n",
        "**● Data preprocessing & handling missing/categorical values**\n",
        "\n",
        "**● Choice between AdaBoost, XGBoost, or CatBoost**\n",
        "\n",
        "**● Hyperparameter tuning strategy**\n",
        "\n",
        "**● Evaluation metrics you'd choose and why**\n",
        "\n",
        "**● How the business would benefit from your model**\n",
        "\n",
        "## **Step-by-Step Data Science Pipeline**\n",
        "\n",
        "### **1. Data Preprocessing**\n",
        "\n",
        "* **Handling Missing Values:**\n",
        "\n",
        "  * For numeric features: fill missing values with `median` (robust to outliers).\n",
        "  * For categorical features: fill missing values with `mode` or `\"Unknown\"`.\n",
        "\n",
        "* **Encoding Categorical Features:**\n",
        "\n",
        "  * Use **One-Hot Encoding** for algorithms like XGBoost or AdaBoost.\n",
        "  * Use **CatBoost’s native handling** for categorical features when using CatBoost.\n",
        "\n",
        "* **Feature Scaling:**\n",
        "\n",
        "  * Not strictly required for boosting models, but may be useful for interpretability.\n",
        "\n",
        "* **Handling Imbalanced Data:**\n",
        "\n",
        "  * Use **SMOTE** or **Random Oversampling** for minority class.\n",
        "  * Alternatively, use **class weights** in the boosting model.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Choice of Boosting Algorithm**\n",
        "\n",
        "| Algorithm    | When to Use                                                                                 |\n",
        "| ------------ | ------------------------------------------------------------------------------------------- |\n",
        "| **AdaBoost** | Simple boosting, works best with clean numeric data                                         |\n",
        "| **XGBoost**  | Handles numeric and categorical (after encoding), powerful, faster                          |\n",
        "| **CatBoost** | Best for categorical-heavy datasets, handles missing values natively, often higher accuracy |\n",
        "\n",
        "**For this dataset:** **CatBoost** is preferred because it handles missing values and categorical features efficiently.\n",
        "\n",
        "\n",
        "### **3. Hyperparameter Tuning Strategy**\n",
        "\n",
        "* Use **GridSearchCV** or **RandomizedSearchCV**.\n",
        "* Important hyperparameters for CatBoost/XGBoost:\n",
        "\n",
        "  * `learning_rate`: Step size for boosting (0.01–0.3)\n",
        "  * `depth`: Tree depth (3–10)\n",
        "  * `iterations/n_estimators`: Number of boosting rounds (100–1000)\n",
        "  * `l2_leaf_reg` / `reg_lambda`: Regularization to prevent overfitting\n",
        "  * `class_weights`: Handle class imbalance\n",
        "\n",
        "\n",
        "### **4. Evaluation Metrics**\n",
        "\n",
        "* **Accuracy** is not sufficient due to imbalance.\n",
        "* Use:\n",
        "\n",
        "  * **Precision** – proportion of predicted defaults that are actual defaults.\n",
        "  * **Recall** – proportion of actual defaults that are correctly predicted.\n",
        "  * **F1-score** – balance between precision and recall.\n",
        "  * **ROC-AUC** – model’s ability to rank default vs non-default.\n",
        "\n",
        "\n",
        "### **5. Business Benefits**\n",
        "\n",
        "* Early detection of potential **loan defaults** helps:\n",
        "\n",
        "  * Reduce financial loss.\n",
        "  * Optimize **credit policies**.\n",
        "  * Targeted interventions for high-risk customers.\n",
        "* Boosting models (like CatBoost) improve predictive accuracy, allowing **better risk management**.\n",
        "\n",
        "\n",
        " **Interpretation:**\n",
        "\n",
        "* High **ROC-AUC** and **F1-score** for the minority class indicate the model reliably predicts defaults.\n",
        "* The business can use this model for **proactive risk mitigation**.\n"
      ],
      "metadata": {
        "id": "Bu6tX3cQTjLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from catboost import CatBoostClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Step 1: Load dataset (replace with your dataset path)\n",
        "# df = pd.read_csv('loan_data.csv')\n",
        "# For demonstration, let's create a dummy dataset\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=6,\n",
        "                           n_redundant=2, n_clusters_per_class=1, weights=[0.8],\n",
        "                           flip_y=0.05, random_state=42)\n",
        "X = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
        "\n",
        "# Step 2: Handle missing values (for demonstration, assume none)\n",
        "# X.fillna(X.median(), inplace=True)\n",
        "\n",
        "# Step 3: Handle imbalanced dataset using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X, y)\n",
        "\n",
        "# Step 4: Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Initialize CatBoost Classifier\n",
        "cat_model = CatBoostClassifier(verbose=0, random_state=42)\n",
        "\n",
        "# Step 6: Hyperparameter tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'depth': [4, 6, 8],\n",
        "    'iterations': [200, 500]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(cat_model, param_grid, scoring='roc_auc', cv=3, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 7: Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Step 8: Evaluate model\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgYsJ2tyUZss",
        "outputId": "1f9dacb4-6675-4275-c5eb-47be2bc929fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'depth': 8, 'iterations': 200, 'learning_rate': 0.05}\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95       160\n",
            "           1       0.97      0.93      0.95       157\n",
            "\n",
            "    accuracy                           0.95       317\n",
            "   macro avg       0.95      0.95      0.95       317\n",
            "weighted avg       0.95      0.95      0.95       317\n",
            "\n",
            "ROC-AUC Score: 0.9852707006369427\n"
          ]
        }
      ]
    }
  ]
}